{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laughing-counter",
   "metadata": {},
   "source": [
    "### MNIST digit classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-environment",
   "metadata": {},
   "source": [
    "Obviously the first thing we do is import the relevent packages for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chemical-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-beast",
   "metadata": {},
   "source": [
    "Now define some parameters, apparently for the MNIST image set the images are 28 pixels square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "several-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 28, 28\n",
    "input_shape = (img_width,img_height,1) # this odd shape is due to use of Conv2D\n",
    "batch_size = 1000                      #and since imgs are greysale\n",
    "no_epochs = 5\n",
    "no_classes = 10 #datase has images of numbers 0-9\n",
    "validation_split = 0.2\n",
    "verbosity = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-certificate",
   "metadata": {},
   "source": [
    "Specifying the model as verbose means to specify all the possible output in the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-fence",
   "metadata": {},
   "source": [
    "Now we need to load the training dataset, keras has some ones saved, including the MNIST image set so we can load it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reserved-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return tensorflow.keras.datasets.mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-phenomenon",
   "metadata": {},
   "source": [
    "Ok now lets actually build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regular-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(4, kernel_size = (3,3), activation = 'relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(8, kernel_size = (3,3), activation = 'relu'))\n",
    "    model.add(Conv2D(12, kernel_size = (3,3), activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dense(no_classes, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-silver",
   "metadata": {},
   "source": [
    "This is the shape of the model that we will be using, however we still have to compile it into a working model. So we need to specify both an optimisation algorithm and a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technological-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model1(model):\n",
    "    model.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
    "                 optimizer = tensorflow.keras.optimizers.Adam(),\n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-highlight",
   "metadata": {},
   "source": [
    "Now we train up the model, making sure to split data into training validation and testing so that we can effectively train a model able to generalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serious-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train):\n",
    "    model.fit(X_train, Y_train, \n",
    "             batch_size = batch_size, \n",
    "             epochs = no_epochs, \n",
    "             verbose = verbosity,\n",
    "             shuffle = True,\n",
    "             validation_split = validation_split\n",
    "             )\n",
    "    return model\n",
    "\n",
    "#now we test the model\n",
    "def test_model(model, X_test, Y_test):\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seven-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we load in the data\n",
    "(X_train, Y_train), (X_test, Y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "experimental-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have to normalise the data\n",
    "(X_train, X_test) = (X_train/255.0, X_test/255.0)\n",
    "\n",
    "#255 because I think this is the maximum value in the greyscale range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-evaluation",
   "metadata": {},
   "source": [
    "Now we reshape the data into the same shape as what the first Conv2D layer of our model is expecting, as we have defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "heard-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "oriental-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "concerned-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/48 [==============================] - 26s 534ms/step - loss: 0.4597 - accuracy: 0.8633 - val_loss: 0.1856 - val_accuracy: 0.9477\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 25s 530ms/step - loss: 0.1437 - accuracy: 0.9584 - val_loss: 0.1019 - val_accuracy: 0.9722\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 26s 545ms/step - loss: 0.0819 - accuracy: 0.9764 - val_loss: 0.0778 - val_accuracy: 0.9777\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 27s 558ms/step - loss: 0.0579 - accuracy: 0.9832 - val_loss: 0.0724 - val_accuracy: 0.9803\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 27s 555ms/step - loss: 0.0455 - accuracy: 0.9870 - val_loss: 0.0698 - val_accuracy: 0.9793\n",
      "Test loss: 0.05624527111649513 / Test accuracy: 0.9814000129699707\n"
     ]
    }
   ],
   "source": [
    "model = model1()\n",
    "model = compile_model1(model)\n",
    "model = train_model(model, X_train, Y_train)\n",
    "model = test_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-drinking",
   "metadata": {},
   "source": [
    "So it seems the output of the model is a length 10 list with each entry being the probability of that index being the predicted number, so I should be able to print the indices of the largest probabilities and this will give us the predicted numbers, I can test this below for the first 10 or something just to show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "palestinian-planning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 answers to test are  [7 2 1 0 4 1 4 9 5 9]\n",
      "First 3 predicted answers are  [7, 2, 1, 0, 4, 1, 4, 9, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "print('First 3 answers to test are ' , Y_test[:10])\n",
    "\n",
    "x=model.predict(X_test)\n",
    "list1=[np.argmax(x[i]) for i in range(10)]\n",
    "print('First 3 predicted answers are ', list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-potential",
   "metadata": {},
   "source": [
    "Works very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-actor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
